{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq.ipynb","provenance":[],"collapsed_sections":["9aFhLXEMw0M7","ROjueuYNurUw"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"30671e52546b4c9fb2c5350d04315344":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b8ea0329c41e49fbab57008de8917218","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7cd1bcc7990a430d9801fc4cf409d467","IPY_MODEL_56aa1bc6e1264a6596c4b8dd4f6bd86d"]}},"b8ea0329c41e49fbab57008de8917218":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7cd1bcc7990a430d9801fc4cf409d467":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e115aaf6b6e54a02aa0176b3c9d315f0","_dom_classes":[],"description":"parsing log, completed traces :: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":150370,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":150370,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bcefb2d59bb947328cfe0f2d7ef05f5c"}},"56aa1bc6e1264a6596c4b8dd4f6bd86d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_763adce6cc434f4992b39b88e3f35d02","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 150370/150370 [16:47&lt;00:00, 149.18it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b9b8da35c1a34906adea456ff6e15585"}},"e115aaf6b6e54a02aa0176b3c9d315f0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bcefb2d59bb947328cfe0f2d7ef05f5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"763adce6cc434f4992b39b88e3f35d02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b9b8da35c1a34906adea456ff6e15585":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"aprYXuoCjDM7"},"source":["# **Resolving Partially Ordered Traces Using Deep Learning** (Seq2Seq)\n"]},{"cell_type":"markdown","metadata":{"id":"RZQouEa5jNye"},"source":["|                        | BPI 2012| BPI 2014 | Traffic |\n","|-----------------------:|--------:|---------:|--------:|\n","| \\|A\\|                  | 24      |  9       | 11      |\n","| #Traces                | 13087   | 41353    | 150370  |\n","| #Events                | 262200  | 369485   | 561470  |\n","| #Event Sets            | 248205  | 243186   | 549452  |\n","| #uncertain Seq's       | 14      | 24       | 25      |\n","| Trace Uncertainty      | 38%     | 93%      |  6%     |\n","| Event Uncertainty      |  5%     | 40%      |  2%     |\n","| max(len(unc.seq))      |  4      |  4       |  3      |\n","| avg(len(unc.seq))      |  2.4    |  2.6     |  2.0    |"]},{"cell_type":"markdown","metadata":{"id":"DDolyTrXjww-"},"source":["### imports and PIP installs"]},{"cell_type":"code","metadata":{"id":"nMdfVhgVxdRN"},"source":["!pip install pm4py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59ipRHAlxWGU","executionInfo":{"status":"ok","timestamp":1622229198453,"user_tz":-120,"elapsed":23031,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}},"outputId":"f2b641c8-10ed-425f-b714-9cfa05837cfa"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LisnrSSLxfmM","executionInfo":{"status":"ok","timestamp":1622229203664,"user_tz":-120,"elapsed":291,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["import sys\n","sys.path.append('/content/drive/MyDrive/Bachelor_Thesis/')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"bYmFOPHyw0Mi","executionInfo":{"status":"ok","timestamp":1622229205562,"user_tz":-120,"elapsed":315,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["import utils"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"jg352xL9j8bX","executionInfo":{"status":"ok","timestamp":1622229212531,"user_tz":-120,"elapsed":5912,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["from tqdm import tqdm\n","import itertools\n","from itertools import combinations_with_replacement, product\n","from random import shuffle\n","from pm4py.objects.log.importer.xes import importer as xes_importer\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","from sklearn import model_selection\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Input, LSTM"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SWVB1eLrkdXa"},"source":["### Loading the logs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["30671e52546b4c9fb2c5350d04315344","b8ea0329c41e49fbab57008de8917218","7cd1bcc7990a430d9801fc4cf409d467","56aa1bc6e1264a6596c4b8dd4f6bd86d","e115aaf6b6e54a02aa0176b3c9d315f0","bcefb2d59bb947328cfe0f2d7ef05f5c","763adce6cc434f4992b39b88e3f35d02","b9b8da35c1a34906adea456ff6e15585"]},"id":"C3epvnhckc3z","executionInfo":{"status":"ok","timestamp":1622235606408,"user_tz":-120,"elapsed":54445,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}},"outputId":"04483032-5412-436d-b63e-bfc1fa8c99e5"},"source":["#b12_log = xes_importer.apply(\"/content/drive/MyDrive/Bachelor_Thesis/logs/BPI_Challenge_2012.xes\")\n","#b14_log = xes_importer.apply(\"/content/drive/MyDrive/Bachelor_Thesis/logs/BPI_Challenge_2014.xes\")\n","traffic_log = xes_importer.apply(\"/content/drive/MyDrive/Bachelor_Thesis/logs/traffic_fines.xes\")"],"execution_count":55,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30671e52546b4c9fb2c5350d04315344","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='parsing log, completed traces :: ', max=150370.0, style=Pâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"07-dTgI6QY9j"},"source":["# artificial logs\n","\n","#a_log0   = xes_importer.apply(\"./logs/generated_logs/1561989897361-4_0.xes\")\n","#a_log25  = xes_importer.apply(\"./logs/generated_logs/1561989897361-4_25.xes\")\n","#a_log50  = xes_importer.apply(\"./logs/generated_logs/1561989897361-4_50.xes\")\n","#a_log75  = xes_importer.apply('/content/drive/MyDrive/Bachelor_Thesis/logs/generated_logs/1561989897313-3_75.xes')\n","#a_log100 = xes_importer.apply(\"./logs/generated_logs/1561989906794-495_100.xes\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UCyHXEpuledB"},"source":["# **Seq2Seq**\n","---"]},{"cell_type":"code","metadata":{"id":"Mu8-KGJm88Kg","executionInfo":{"status":"ok","timestamp":1622236577689,"user_tz":-120,"elapsed":11443,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["log = utils.remove_timezones(traffic_log)\n","#utils.abstract_time(log, utils.abstract_seconds) # AF abstract to minutes for the artificial logs\n","c_log, u_log = utils.split_log(log)\n","\n","sparse_log = utils.get_sparse_log(log)\n","sparse_c_log, sparse_u_log = utils.get_sparse_log(c_log), utils.get_sparse_log(u_log)\n","\n","A = list(set([event[\"concept:name\"] for trace in log for event in trace ]))\n","A_set = [[activity] for activity in A]\n","\n","#log_set   = utils.get_sparse_log_set(log)      \n","#c_log_set = utils.get_sparse_log_set(c_log)\n","#u_log_set = utils.get_sparse_log_set(u_log)\n","\n","log_set   = utils.get_sparse_log_set_artificial(log)     # AF build log sets for the artificial logs, i.e. only direct neighbor with equal timestamps are equal \n","c_log_set = utils.get_sparse_log_set_artificial(c_log)\n","u_log_set = utils.get_sparse_log_set_artificial(u_log)"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"nm-xfAZxw0Mu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622236577692,"user_tz":-120,"elapsed":31,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}},"outputId":"48434ff9-1ce5-467d-dbc9-022ba4a30a2a"},"source":["max_trace_len = utils.longest_trace(u_log)\n","max_unc_trace_len = utils.longest_trace(u_log_set)\n","max_seq_len = utils.longest_unc_seq(u_log_set)\n","k = max_seq_len # longest uncertain sequences\n","print(k)"],"execution_count":57,"outputs":[{"output_type":"stream","text":["3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cIylMmZYlhxT","executionInfo":{"status":"ok","timestamp":1622236579310,"user_tz":-120,"elapsed":16,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["unc_seq = utils.possible_uncertain_seq(A, k) \n","pos_res = utils.possible_resolutions(A, k)"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ZA6zxmwDDjr","executionInfo":{"status":"ok","timestamp":1622236582808,"user_tz":-120,"elapsed":274,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}},"outputId":"75949f7d-53ca-4448-c5f5-4272e5dd15d0"},"source":["NAME = \"concept:name\"\n","TIME = \"time:timestamp\"\n","for event in log[555]: \n","  print(\"{:20} at   {}\".format(event[NAME], event[TIME]))"],"execution_count":59,"outputs":[{"output_type":"stream","text":["Create Fine          at   2007-04-16 02:00:00\n","Payment              at   2007-04-16 02:00:00\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RSgN5py9w0Mw","executionInfo":{"status":"ok","timestamp":1622236586016,"user_tz":-120,"elapsed":356,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["pos_res_for_unc_seq = utils.pos_res_for_unc_seq(unc_seq)"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"y9Eohyumw0Mx","executionInfo":{"status":"ok","timestamp":1622236586760,"user_tz":-120,"elapsed":9,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["# add start and end sequence symbol to each target trace\n","BOS = '<'\n","EOS = '>'"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"crk-IYRvw0My","executionInfo":{"status":"ok","timestamp":1622236588913,"user_tz":-120,"elapsed":242,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["# shrink the set if it is larger 10000 to 10000 \n","# since the smallest set has about 10000 (traffic log) \n","# also for huge encoding 2, 3\n","c = list(zip(u_log_set, sparse_u_log))\n","shuffle(c)\n","u_log_set, sparse_u_log = zip(*c)\n","u_log_set, sparse_u_log = list(u_log_set), list(sparse_u_log)\n","\n","enc1 = True\n","\n","if len(u_log_set) > 10000:\n","    u_log_set = u_log_set[:10000]         # this is dec_X\n","    sparse_u_log = sparse_u_log[:10000]   # this is dec_y"],"execution_count":62,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yZXF4f_2w0Mz"},"source":["### Encoding 1"]},{"cell_type":"code","metadata":{"id":"n2uRlLwQw0M0","executionInfo":{"status":"ok","timestamp":1622236593676,"user_tz":-120,"elapsed":223,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["rev_X = [trace[::-1] for trace in u_log_set] \n","y = [[BOS] + seq + [EOS] for seq in sparse_u_log]"],"execution_count":63,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kPWF7FuRw0M1","executionInfo":{"status":"ok","timestamp":1622236594605,"user_tz":-120,"elapsed":7,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}},"outputId":"852e29b9-243c-4dd5-f495-9a3eddb3f228"},"source":["input_events = A\n","target_events = sorted(A + [BOS, EOS])\n","n_enc_tokens = len(input_events)\n","n_dec_tokens = len(target_events)\n","max_enc_seq_len = max([len(trace) for trace in rev_X])\n","max_dec_seq_len = max([len(trace) for trace in y])\n","\n","print('Number of samples:', len(rev_X))\n","print('Number of unique input tokens:', n_enc_tokens)\n","print('Number of unique output tokens:', n_dec_tokens)\n","print('Max sequence length for inputs:', max_enc_seq_len)\n","print('Max sequence length for outputs:', max_dec_seq_len)"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Number of samples: 9166\n","Number of unique input tokens: 11\n","Number of unique output tokens: 13\n","Max sequence length for inputs: 18\n","Max sequence length for outputs: 22\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yyoHD46Lw0M4","executionInfo":{"status":"ok","timestamp":1622236597762,"user_tz":-120,"elapsed":8,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["# lookup tables\n","INactivity_to_idx = dict( (tuple(e_set),i) for i,e_set in enumerate(input_events)) \n","INidx_to_activity = dict( (i,tuple(e_set)) for i,e_set in enumerate(input_events))\n","INactivity_to_idx2 = dict( (e_set,i) for i,e_set in enumerate(input_events)) # for decoding\n","INidx_to_activity2 = dict( (i,e_set) for i,e_set in enumerate(input_events)) # for decoding\n","\n","OUTactivity_to_idx = dict( (tuple(e_set),i) for i,e_set in enumerate(target_events))\n","OUTidx_to_activity = dict( (i,tuple(e_set)) for i,e_set in enumerate(target_events))\n","OUTactivity_to_idx2 = dict( (e_set,i) for i,e_set in enumerate(target_events)) # for decoding\n","OUTidx_to_activity2 = dict( (i,e_set) for i,e_set in enumerate(target_events)) # for decoding"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"id":"mDOms4wiw0M6","executionInfo":{"status":"ok","timestamp":1622236599777,"user_tz":-120,"elapsed":529,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["encoder_input_data, decoder_input_data, decoder_target_data = utils.seq2seq_encode(rev_X, y, max_enc_seq_len, n_enc_tokens,\n","                                                                            max_dec_seq_len, n_dec_tokens, INactivity_to_idx,\n","                                                                            OUTactivity_to_idx, 1)"],"execution_count":66,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9aFhLXEMw0M7"},"source":["### Encoding 2 & 3"]},{"cell_type":"code","metadata":{"id":"nSBSWdpIw0M8"},"source":["rev_X = [trace_set[::-1] for trace_set in u_log_set]\n","y = [[[BOS]] + seq + [[EOS]] for seq in u_log_set]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rvzYhLPPw0M-","outputId":"1ea6dd81-b0eb-4099-999d-c5234d6c3b1f"},"source":["input_events = unc_seq\n","target_events = sorted(pos_res + [[BOS], [EOS]])\n","n_enc_tokens = len(input_events)\n","n_dec_tokens = len(target_events)\n","max_enc_seq_len = max([len(trace) for trace in rev_X]) # fix here\n","max_dec_seq_len = max([len(trace) for trace in y])\n","\n","print('Number of samples:', len(rev_X))\n","print('Number of unique input tokens:', n_enc_tokens)\n","print('Number of unique output tokens:', n_dec_tokens)\n","print('Max sequence length for inputs:', max_enc_seq_len)\n","print('Max sequence length for outputs:', max_dec_seq_len)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of samples: 10000\n","Number of unique input tokens: 714\n","Number of unique output tokens: 7382\n","Max sequence length for inputs: 91\n","Max sequence length for outputs: 93\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"76J0a5QLw0NC"},"source":["# lookup tables\n","unc_seq_to_idx = dict( (tuple(e_set),i) for i,e_set in enumerate(input_events)) \n","idx_to_unc_seq = dict( (i,tuple(e_set)) for i,e_set in enumerate(input_events))\n","\n","pos_res_to_idx = dict( (tuple(e_set),i) for i,e_set in enumerate(target_events))\n","idx_to_pos_res = dict( (i,tuple(e_set)) for i,e_set in enumerate(target_events))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G-U4mgeTw0ND"},"source":["Encoding 2"]},{"cell_type":"code","metadata":{"id":"_GGWvkD5w0NE"},"source":["encoder_input_data, decoder_input_data, decoder_target_data = utils.seq2seq_encode(rev_X, y, max_enc_seq_len, n_enc_tokens,\n","                                                                            max_dec_seq_len, n_dec_tokens, unc_seq_to_idx,\n","                                                                            pos_res_to_idx, 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fYL9yxjew0NF"},"source":["Encoding 3"]},{"cell_type":"code","metadata":{"id":"MkT09x_nw0NF"},"source":["encoder_input_data, decoder_input_data, decoder_target_data = utils.seq2seq_encode(rev_X, y, max_enc_seq_len, n_enc_tokens,\n","                                                                            max_dec_seq_len, n_dec_tokens, unc_seq_to_idx,\n","                                                                            pos_res_to_idx, 3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VMKnY7_Nw0NG"},"source":["### split inot train and test set (test size 20%)"]},{"cell_type":"code","metadata":{"id":"P22Eu_K-w0NH","executionInfo":{"status":"ok","timestamp":1622236603898,"user_tz":-120,"elapsed":228,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["n_samples = len(rev_X)\n","cut = int(n_samples*0.8)\n","#training\n","train_encoder_input_data  = encoder_input_data[:cut]\n","train_decoder_input_data  = decoder_input_data[:cut]\n","train_decoder_target_data = decoder_target_data[:cut]\n","\n","# test\n","test_encoder_input_data = encoder_input_data[cut:]\n","test_decoder_input_data = decoder_input_data[cut:]\n","test_decoder_target_data = decoder_target_data[cut:]"],"execution_count":67,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o1YxQ9lyw0NJ","executionInfo":{"status":"ok","timestamp":1622236605960,"user_tz":-120,"elapsed":238,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}},"outputId":"a51e75f4-46de-4309-f9ee-a5624843623d"},"source":["train_encoder_input_data.shape, test_encoder_input_data.shape"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((7332, 18, 11), (1834, 18, 11))"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"markdown","metadata":{"id":"bew3aU1Mw0NK"},"source":["## Model (Preprocessing, Training, Predictions, Evaluation)"]},{"cell_type":"code","metadata":{"id":"dxp-Ftwkmo1g","executionInfo":{"status":"ok","timestamp":1622236607649,"user_tz":-120,"elapsed":9,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["batch_size = 64  # batch size for training\n","epochs = 30 # 50  # number of epochs to train for, 100\n","latent_dim = 256  # latent dimensionality of the encoding space\n","callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3) # early stopping when no improvement on loss in 3 consequtive epochs"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"RmkvqwgOmyJM","executionInfo":{"status":"ok","timestamp":1622236608686,"user_tz":-120,"elapsed":709,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["encoder_inputs = Input(shape=(None, n_enc_tokens))\n","encoder = LSTM(latent_dim, return_state=True)\n","encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n","encoder_states = [state_h, state_c]\n","\n","decoder_inputs = Input(shape=(None, n_dec_tokens))\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","decoder_dense = Dense(n_dec_tokens, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","model = Model(inputs=[encoder_inputs, decoder_inputs], \n","              outputs=decoder_outputs)"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"I8-Q12F_nTA7","executionInfo":{"status":"ok","timestamp":1622236610971,"user_tz":-120,"elapsed":331,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","#model.summary()"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sO6MLrLJnu-K","executionInfo":{"status":"ok","timestamp":1622237169863,"user_tz":-120,"elapsed":556957,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}},"outputId":"93402783-a286-4699-e4ce-b0118842716e"},"source":["history = model.fit([train_encoder_input_data, train_decoder_input_data], train_decoder_target_data,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_split=0.2,\n","          callbacks=[callback])"],"execution_count":72,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","92/92 [==============================] - 25s 210ms/step - loss: 0.2645 - val_loss: 0.2078\n","Epoch 2/30\n","92/92 [==============================] - 18s 196ms/step - loss: 0.1761 - val_loss: 0.1472\n","Epoch 3/30\n","92/92 [==============================] - 18s 200ms/step - loss: 0.1473 - val_loss: 0.1328\n","Epoch 4/30\n","92/92 [==============================] - 18s 201ms/step - loss: 0.1272 - val_loss: 0.1108\n","Epoch 5/30\n","92/92 [==============================] - 18s 199ms/step - loss: 0.1094 - val_loss: 0.0963\n","Epoch 6/30\n","92/92 [==============================] - 18s 194ms/step - loss: 0.0947 - val_loss: 0.0897\n","Epoch 7/30\n","92/92 [==============================] - 19s 208ms/step - loss: 0.0902 - val_loss: 0.0818\n","Epoch 8/30\n","92/92 [==============================] - 19s 208ms/step - loss: 0.0855 - val_loss: 0.0824\n","Epoch 9/30\n","92/92 [==============================] - 18s 198ms/step - loss: 0.0830 - val_loss: 0.0805\n","Epoch 10/30\n","92/92 [==============================] - 18s 199ms/step - loss: 0.0808 - val_loss: 0.0796\n","Epoch 11/30\n","92/92 [==============================] - 19s 202ms/step - loss: 0.0782 - val_loss: 0.0757\n","Epoch 12/30\n","92/92 [==============================] - 18s 191ms/step - loss: 0.0756 - val_loss: 0.0742\n","Epoch 13/30\n","92/92 [==============================] - 18s 196ms/step - loss: 0.0724 - val_loss: 0.0723\n","Epoch 14/30\n","92/92 [==============================] - 18s 192ms/step - loss: 0.0689 - val_loss: 0.0688\n","Epoch 15/30\n","92/92 [==============================] - 18s 198ms/step - loss: 0.0637 - val_loss: 0.0620\n","Epoch 16/30\n","92/92 [==============================] - 18s 195ms/step - loss: 0.0600 - val_loss: 0.0608\n","Epoch 17/30\n","92/92 [==============================] - 18s 194ms/step - loss: 0.0578 - val_loss: 0.0578\n","Epoch 18/30\n","92/92 [==============================] - 18s 196ms/step - loss: 0.0545 - val_loss: 0.0564\n","Epoch 19/30\n","92/92 [==============================] - 18s 201ms/step - loss: 0.0518 - val_loss: 0.0518\n","Epoch 20/30\n","92/92 [==============================] - 19s 204ms/step - loss: 0.0489 - val_loss: 0.0492\n","Epoch 21/30\n","92/92 [==============================] - 18s 200ms/step - loss: 0.0457 - val_loss: 0.0502\n","Epoch 22/30\n","92/92 [==============================] - 17s 189ms/step - loss: 0.0454 - val_loss: 0.0450\n","Epoch 23/30\n","92/92 [==============================] - 18s 196ms/step - loss: 0.0435 - val_loss: 0.0436\n","Epoch 24/30\n","92/92 [==============================] - 19s 202ms/step - loss: 0.0439 - val_loss: 0.0421\n","Epoch 25/30\n","92/92 [==============================] - 19s 204ms/step - loss: 0.0379 - val_loss: 0.0400\n","Epoch 26/30\n","92/92 [==============================] - 18s 201ms/step - loss: 0.0353 - val_loss: 0.0374\n","Epoch 27/30\n","92/92 [==============================] - 20s 213ms/step - loss: 0.0361 - val_loss: 0.0385\n","Epoch 28/30\n","92/92 [==============================] - 18s 200ms/step - loss: 0.0350 - val_loss: 0.0356\n","Epoch 29/30\n","92/92 [==============================] - 18s 198ms/step - loss: 0.0329 - val_loss: 0.0341\n","Epoch 30/30\n","92/92 [==============================] - 19s 205ms/step - loss: 0.0347 - val_loss: 0.0355\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eVMPpprzw0NN"},"source":["model.save('./outputs/seq2seqsets_bpi14log_logorder_01022021.h5') "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gjnVDrij6G8Z"},"source":["### Make Predictions"]},{"cell_type":"code","metadata":{"id":"25LUuWtbLtyc","executionInfo":{"status":"ok","timestamp":1622240177681,"user_tz":-120,"elapsed":322,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["#use the trained model to make predictions via inferencing\n","#for that we take the uncertain log as input and assume the order in the log as the correct order\n","\n","#inference mode brakedown\n","# 1 encode input sequence and return corresponding internal states\n","# 2 start decoder with BOS symbol and the encoders internal states as input\n","# 3 append predicted activity (after looking up in lookup table) to the predicted sequence\n","# 4 repeat process with the previously predicted activity and the updated internal states as input\n","# 5 end when EOS was predicted\n","\n","encoder_model = Model(encoder_inputs, encoder_states)\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n","                      [decoder_outputs] + decoder_states)"],"execution_count":73,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ROjueuYNurUw"},"source":["### Evaluation of Encoding 2 and 3"]},{"cell_type":"code","metadata":{"id":"z3yY9Mv2TcWV"},"source":["# build function to decode predictions \n","def decode_seq(enc_input_seq, dec_input_seq, OUTact_to_idx, OUTidx_to_act):\n","    # encode the input sequence to get the internal state vectors\n","    states_value = encoder_model.predict(enc_input_seq)\n","\n","    # generate empty target sequence of len 1 with only the start character\n","    target_seq = np.zeros((1,1, n_dec_tokens))\n","    target_seq[0, 0, OUTact_to_idx[tuple([BOS])]] = 1.0\n","\n","    #output seq loop\n","    stop_cond = False\n","    decoded_trace = []\n","    num_dec_events = 0\n","    while not stop_cond:\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        #sample token and add corresponding activity to the decoded trace\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_activity = list(OUTidx_to_act[sampled_token_index]) \n","        \n","        #print(sampled_activity)\n","        #print(pos_res_for_unc_seq[tuple(dec_input_seq[num_dec_events])])\n","        \n","        # check if the sampled activity is actually a possible resolution fo that case\n","        while not sampled_activity in pos_res_for_unc_seq[tuple(dec_input_seq[num_dec_events])]:\n","            # if not take the prediction with the 2nd highest prob... etc.\n","            output_tokens[0, -1, sampled_token_index] = 0.0 # set the old idx with max prob to zero\n","            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","            sampled_activity = list(OUTidx_to_act[sampled_token_index])\n","            \n","            # check if all idx that had a prob > 0 where turned to 0\n","            # i.e. all of the possible resolution were not considered likely at all\n","            if np.all(output_tokens[0, -1]):\n","                print('BREAK: no prob...')\n","                sampled_activity = ['BREAK']\n","                break\n","        \n","        decoded_trace.append(sampled_activity)\n","        num_dec_events += 1\n","\n","        #check for stop condition: either hitting max length or prediciting EOS\n","        if (sampled_activity == tuple([EOS]) or len(decoded_trace) > max_dec_seq_len or\n","            num_dec_events >= len(dec_input_seq) ):\n","            stop_cond = True\n","\n","        #update the target sequence (len 1)\n","        target_seq = np.zeros((1, 1, n_dec_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.0\n","\n","        #update states\n","        states_value = [h, c]\n","\n","    return decoded_trace "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uBln9ghDw0NU"},"source":["decoded_X_test = utils.decode_X(test_encoder_input_data, idx_to_unc_seq, mode=\"enc2\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fWiGP1cjw0NV","scrolled":true},"source":["for idx in range(0,20):\n","    enc_input_seq = test_encoder_input_data[idx:idx+1]\n","    decoded_trace = [list(trace) for trace in decode_seq(enc_input_seq, decoded_X_test[idx][::-1],\n","                                                         pos_res_to_idx,\n","                                                         idx_to_pos_res)]\n","    print('-'*20)\n","    print('Input trace  :', decoded_X_test[idx][::-1]) # log_set[idx]\n","    print('Decoded trace:', decoded_trace[:])\n","    print(decoded_X_test[idx][::-1]==decoded_trace[:])\n","    print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uOcpfx5Eut0d","outputId":"cd82052c-654a-4d6f-8d64-d0dce50c6e94"},"source":["total = len(decoded_X_test)\n","count = 0\n","for idx in tqdm(range(total)):\n","    enc_input_seq = test_encoder_input_data[idx:idx+1]\n","    decoded_trace = [list(trace) for trace in decode_seq(enc_input_seq, \n","                                                         decoded_X_test[idx][::-1],\n","                                                         pos_res_to_idx,\n","                                                         idx_to_pos_res)]\n","    if decoded_X_test[idx][::-1] == decoded_trace[:]:\n","        count += 1\n","    #print(decoded_X[idx][::-1]==decoded_trace[:])\n","print(count / total)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [10:40<00:00,  3.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["0.177\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"YWQJTf1fw0Nb"},"source":["### Special Case for ambiguous Encoding 1 "]},{"cell_type":"code","metadata":{"id":"WTpRGck1rrvv","executionInfo":{"status":"ok","timestamp":1622240180224,"user_tz":-120,"elapsed":7,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["dec_X_test = u_log_set[cut:]\n","dec_y_test = sparse_u_log[cut:]"],"execution_count":74,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0vK2dEqJZ_Dx"},"source":["taking advantage of information about the prediction to make (length, uncertain sets size, ...)"]},{"cell_type":"code","metadata":{"id":"xrddqYT3ZsfA"},"source":["# -> instead of decoding we stay in order and use the unencoded inputs \n","for idx in range(0,5):\n","    enc_input_seq = test_encoder_input_data[idx:idx+1]\n","    decoded_trace = decode_seq12(enc_input_seq, dec_X_test[idx],\n","                                           OUTactivity_to_idx2,\n","                                           OUTidx_to_activity2)\n","    print('-'*20)\n","    print(\"Source   :\" ,dec_X_test[idx])\n","    print(\"Predicted:\",decoded_trace)\n","    print(\"Target   :\", dec_y_test[idx])\n","    print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CWDBhW9xIgcc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622240639818,"user_tz":-120,"elapsed":450503,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}},"outputId":"8214c2c6-5c16-4dce-e28b-e7588eaf2dce"},"source":["total = test_encoder_input_data.shape[0]\n","n_event_sets = sum([1 for trace in dec_X_test for event_set in trace])\n","count = 0\n","count_highest_prob_is_non_pos_res = 0\n","prediction_probabilities = {}\n","actual_resolution_probabilities = {}\n","\n","for idx in range(total):\n","  enc_input_seq = test_encoder_input_data[idx:idx+1]\n","  decoded_trace = decode_seq12(enc_input_seq, dec_X_test[idx],\n","                               OUTactivity_to_idx2, OUTidx_to_activity2,\n","                               count_highest_prob_is_non_pos_res,\n","                               prediction_probabilities,\n","                               actual_resolution_probabilities)\n","  if dec_y_test[idx]  == decoded_trace:\n","    count += 1\n","  #else:\n","    #print(\"MISPREDICTED\")\n","    #print(\"Source   :\" ,dec_X_test[idx])\n","    #print(\"Predicted:\",decoded_trace)\n","    #print(\"Target   :\", dec_y_test[idx])\n","    #print()\n","  if idx%100 == 0:\n","    print(\"Source   :\" ,dec_X_test[idx])\n","    print(\"Predicted:\",decoded_trace)\n","    print(\"Target   :\", dec_y_test[idx])\n","    print()\n","print(count / total, count_highest_prob_is_non_pos_res / n_event_sets)"],"execution_count":76,"outputs":[{"output_type":"stream","text":["Source   : [['Create Fine'], ['Send Fine'], ['Insert Fine Notification'], ['Add penalty', 'Payment']]\n","Predicted: ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Payment']\n","Target   : ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Payment']\n","\n","Source   : [['Create Fine', 'Payment']]\n","Predicted: ['Create Fine', 'Payment']\n","Target   : ['Create Fine', 'Payment']\n","\n","Source   : [['Create Fine', 'Payment']]\n","Predicted: ['Create Fine', 'Payment']\n","Target   : ['Create Fine', 'Payment']\n","\n","Source   : [['Create Fine'], ['Send Fine'], ['Insert Fine Notification'], ['Add penalty'], ['Insert Date Appeal to Prefecture', 'Send Appeal to Prefecture']]\n","Predicted: ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Insert Date Appeal to Prefecture', 'Send Appeal to Prefecture']\n","Target   : ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Insert Date Appeal to Prefecture', 'Send Appeal to Prefecture']\n","\n","Source   : [['Create Fine', 'Payment']]\n","Predicted: ['Create Fine', 'Payment']\n","Target   : ['Create Fine', 'Payment']\n","\n","Source   : [['Create Fine', 'Payment']]\n","Predicted: ['Create Fine', 'Payment']\n","Target   : ['Create Fine', 'Payment']\n","\n","Source   : [['Create Fine', 'Payment']]\n","Predicted: ['Create Fine', 'Payment']\n","Target   : ['Create Fine', 'Payment']\n","\n","Source   : [['Create Fine', 'Payment']]\n","Predicted: ['Create Fine', 'Payment']\n","Target   : ['Create Fine', 'Payment']\n","\n","Source   : [['Create Fine', 'Send Fine', 'Insert Fine Notification'], ['Add penalty'], ['Send for Credit Collection']]\n","Predicted: ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Send for Credit Collection']\n","Target   : ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Send for Credit Collection']\n","\n","Source   : [['Create Fine', 'Payment']]\n","Predicted: ['Create Fine', 'Payment']\n","Target   : ['Create Fine', 'Payment']\n","\n","Source   : [['Create Fine', 'Send Fine', 'Insert Fine Notification'], ['Add penalty'], ['Send for Credit Collection']]\n","Predicted: ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Send for Credit Collection']\n","Target   : ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Send for Credit Collection']\n","\n","Source   : [['Create Fine', 'Payment']]\n","Predicted: ['Create Fine', 'Payment']\n","Target   : ['Create Fine', 'Payment']\n","\n","Source   : [['Create Fine', 'Payment']]\n","Predicted: ['Create Fine', 'Payment']\n","Target   : ['Create Fine', 'Payment']\n","\n","Source   : [['Create Fine', 'Send Fine', 'Insert Fine Notification'], ['Add penalty', 'Payment']]\n","Predicted: ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Payment']\n","Target   : ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Payment']\n","\n","Source   : [['Create Fine', 'Payment']]\n","Predicted: ['Create Fine', 'Payment']\n","Target   : ['Create Fine', 'Payment']\n","\n","Source   : [['Create Fine'], ['Send Fine'], ['Insert Fine Notification'], ['Payment'], ['Add penalty', 'Payment']]\n","Predicted: ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Payment', 'Add penalty', 'Payment']\n","Target   : ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Payment', 'Add penalty', 'Payment']\n","\n","Source   : [['Create Fine', 'Payment']]\n","Predicted: ['Create Fine', 'Payment']\n","Target   : ['Create Fine', 'Payment']\n","\n","Source   : [['Create Fine', 'Send Fine', 'Insert Fine Notification'], ['Add penalty'], ['Send for Credit Collection']]\n","Predicted: ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Send for Credit Collection']\n","Target   : ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Send for Credit Collection']\n","\n","Source   : [['Create Fine', 'Send Fine', 'Insert Fine Notification'], ['Add penalty'], ['Payment'], ['Payment']]\n","Predicted: ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Payment', 'Payment']\n","Target   : ['Create Fine', 'Send Fine', 'Insert Fine Notification', 'Add penalty', 'Payment', 'Payment']\n","\n","0.9858233369683751 0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z_RV6WE_6b68","executionInfo":{"status":"ok","timestamp":1622240185020,"user_tz":-120,"elapsed":219,"user":{"displayName":"Glenn Dittmann","photoUrl":"","userId":"09282768545803181559"}}},"source":["# build funtion to decode predictions \n","def decode_seq12(enc_input_seq, dec_input_seq, OUTact_to_idx, OUTidx_to_act, count_highest_prob_is_non_pos_res,\n","                 prediction_probabilities, actual_resolution_probabilities):\n","    # encode the input sequence to get the internal state vectors\n","    states_value = encoder_model.predict(enc_input_seq)\n","\n","    # generate empty target sequence of len 1 with only the start character\n","    target_seq = np.zeros((1,1, n_dec_tokens))\n","    target_seq[0, 0, OUTact_to_idx[BOS]] = 1.0\n","\n","    #output seq loop\n","    stop_cond = False\n","    decoded_trace = []\n","\n","    e_set_len = [len(event_set) for event_set in dec_input_seq]       # length of each uncertain set\n","    indices = [0 for length in e_set_len]                             # start indices of the uncertain set in the y_trace e.g. [[A,B], [C], [D,E]]\n","                                                                      #                                                   with [A, B, C, D, E] -> [0, 2, 3]\n","    for i in range(len(e_set_len[:-1])):\n","      indices[i+1] = indices[i] + e_set_len[i]\n","\n","\n","    for i in range(len(dec_input_seq)): # iterate over all event sets\n","          \n","      events_to_predict = dec_input_seq[i].copy() # the events to be predicted\n","          \n","      for j in range(e_set_len[i]): \n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        # sample token and add corresponding activity to the decoded trace\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_activity = OUTidx_to_act[sampled_token_index]\n","        \n","        if sampled_activity == EOS: # end of sequence reached, i.e. event_to_predict == empty set\n","          #print(EOS)\n","          break\n","          \n","        # check if the sampled activity is actually a possible resolution for that trace\n","        # if not take the prediction with the 2nd highest prob... etc.\n","        while not sampled_activity in (events_to_predict):\n","          output_tokens[0, -1, sampled_token_index] = 0.0             # set the old idx with max prob to zero\n","          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","          sampled_activity = OUTidx_to_act[sampled_token_index]\n","\n","        # the predicted activity must be removed from the activity to be predicted, so it won't be predicted again --> obtain possible resolution\n","        events_to_predict.remove(sampled_activity)\n","\n","        decoded_trace.append(sampled_activity)\n","\n","        #update the target sequence (len 1)\n","        target_seq = np.zeros((1, 1, n_dec_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.0\n","\n","        #update states\n","        states_value = [h, c]\n","\n","    return decoded_trace"],"execution_count":75,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zNi108V_Z5qk"},"source":["### dynamic evaluation"]},{"cell_type":"code","metadata":{"id":"BrIbQLUTw0Nc","scrolled":true},"source":["# -> instead of decoding we stay in order and use the unencoded inputs \n","for idx in range(0,20):\n","    enc_input_seq = test_encoder_input_data[idx:idx+1]\n","    decoded_trace = decode_seq1(enc_input_seq, dec_X_test[idx],\n","                                           OUTactivity_to_idx2,\n","                                           OUTidx_to_activity2)\n","    print('-'*20)\n","    print(\"Source   :\" ,dec_X_test[idx])\n","    print(\"Predicted:\",decoded_trace)\n","    print(\"Target   :\", dec_y_test[idx])\n","    print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qoN8E2UMw0Ne"},"source":["total = test_encoder_input_data.shape[0]\n","count = 0\n","for idx in range(total):\n","  enc_input_seq = test_encoder_input_data[idx:idx+1]\n","  decoded_trace = decode_seq1(enc_input_seq, dec_X_test[idx],\n","                                         OUTactivity_to_idx2,\n","                                         OUTidx_to_activity2)\n","  if dec_y_test[idx]  == decoded_trace[:]:\n","    count += 1\n","  print(\"Source   :\" ,dec_X_test[idx])\n","  print(\"Predicted:\",decoded_trace)\n","  print(\"Target   :\", dec_y_test[idx])\n","  print()\n","print(count / total)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eFCBX5iYw0Nh"},"source":["# build funtion to decode predictions \n","def decode_seq1(enc_input_seq, dec_input_seq, OUTact_to_idx, OUTidx_to_act):\n","    # encode the input sequence to get the internal state vectors\n","    states_value = encoder_model.predict(enc_input_seq)\n","\n","    # generate empty target sequence of len 1 with only the start character\n","    target_seq = np.zeros((1,1, n_dec_tokens))\n","    target_seq[0, 0, OUTact_to_idx[BOS]] = 1.0\n","\n","    #output seq loop\n","    stop_cond = False\n","    decoded_trace = []\n","    n_dec_events = 0\n","    n_repetitions = len(dec_input_seq[n_dec_events])\n","    while not stop_cond:\n","        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","        # sample token and add corresponding activity to the decoded trace\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_activity = [OUTidx_to_act[sampled_token_index]] \n","        \n","        if len(dec_input_seq[n_dec_events]) > 1: # if we have an event set > 1 in input we need to consider it multiple times\n","            must_be_in = pos_res_for_unc_seq[tuple(sorted(dec_input_seq[n_dec_events]))] + [[activity] for activity in pos_res_for_unc_seq[tuple(sorted(dec_input_seq[n_dec_events]))][0]]\n","        else:\n","            must_be_in = pos_res_for_unc_seq[tuple(sorted(dec_input_seq[n_dec_events]))]\n","    \n","        #print(\"pred: \", sampled_activity)\n","        #print(\"must be in: \", must_be_in)\n","        \n","        # check if the sampled activity is actually a possible resolution for that trace\n","        while not sampled_activity in (must_be_in):\n","            # if not take the prediction with the 2nd highest prob... etc.\n","            output_tokens[0, -1, sampled_token_index] = 0.0 # set the old idx with max prob to zero\n","            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","            sampled_activity = [OUTidx_to_act[sampled_token_index]]\n","        \n","        decoded_trace.append(sampled_activity)\n","        \n","        if n_repetitions > 1:\n","            n_repetitions -= 1\n","        else:\n","            n_dec_events += 1\n","            if n_dec_events < len(dec_input_seq): \n","                n_repetitions = len(dec_input_seq[n_dec_events])\n","\n","        #check for stop condition: either hitting max length or prediciting EOS\n","        if (sampled_activity == tuple([EOS]) or len(decoded_trace) > max_dec_seq_len or\n","            n_dec_events >= len(dec_input_seq) ):\n","            stop_cond = True\n","\n","        #update the target sequence (len 1)\n","        target_seq = np.zeros((1, 1, n_dec_tokens))\n","        target_seq[0, 0, sampled_token_index] = 1.0\n","\n","        #update states\n","        states_value = [h, c]\n","\n","    return list(itertools.chain(*decoded_trace))"],"execution_count":null,"outputs":[]}]}