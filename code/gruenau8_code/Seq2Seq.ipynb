{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aprYXuoCjDM7"
   },
   "source": [
    "# **Resolving Partially Ordered Traces Using Deep Learning** (Seq2Seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZQouEa5jNye"
   },
   "source": [
    "|                        | BPI 2012| BPI 2014 | Traffic | <br>\n",
    "|-----------------------:|--------:|---------:|--------:|\n",
    "| \\|A\\|                  | 24      |  9       | 11      |\n",
    "| #Traces                | 13087   | 41353    | 150370  |\n",
    "| #Events                | 262200  | 369485   | 561470  |\n",
    "| #Event Sets            | 248205  | 243186   | 549452  |\n",
    "| #uncertain Seq's       | 14      | 24       | 25      |\n",
    "| Trace Uncertainty      | 38%     | 93%      |  6%     |\n",
    "| Event Uncertainty      |  5%     | 40%      |  2%     |\n",
    "| max(len(unc.seq))      |  4      |  4       |  3      |\n",
    "| avg(len(unc.seq))      |  2.4    |  2.6     |  2.0    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDolyTrXjww-"
   },
   "source": [
    "### imports and PIP installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7lUJcTbHisjt",
    "outputId": "3cc089f0-e09b-4461-9ef6-83eec44c16aa"
   },
   "outputs": [],
   "source": [
    "from pm4py.objects.log.importer.xes import importer as xes_importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jg352xL9j8bX"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import combinations_with_replacement, product\n",
    "from random import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import model_selection\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWVB1eLrkdXa"
   },
   "source": [
    "### Loading the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "17fbd2a891c246b1ad644861df42aa9f",
      "c4b08832d5274e6abdceb831e0bbe4d1",
      "c6ec3586c3e24fac9ab8124f2a508250",
      "b2b5c49f02404eb29bb2b33b3f7b5d64",
      "e0aa799ebe894bf380c94bdcda32c76b",
      "8033e5669f8e4a359a802bbd3e056518",
      "a4e455a34a5e47f99b310614cf320832",
      "7c1f1a33df154d5bace2efc5e29f6b6a"
     ]
    },
    "id": "C3epvnhckc3z",
    "outputId": "72c08d3d-9c73-4b0b-a53e-af5fae6a416c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c5442fdbac4fbe9475573b3e2c357d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='parsing log, completed traces :: ', max=150370.0, style=P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#b12_log = xes_importer.apply(\"./logs/BPI_Challenge_2012.xes\")\n",
    "#b14_log = xes_importer.apply(\"./logs/BPI_Challenge_2014.xes\")\n",
    "#traffic_log = xes_importer.apply(\"./logs/traffic_fines.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77b997496ea4ce5bcf726384e4fd3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='parsing log, completed traces :: ', max=1000.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# artificial logs\n",
    "\n",
    "#a_log0   = xes_importer.apply(\"./logs/generated_logs/1561989897361-4_0.xes\")\n",
    "#a_log25  = xes_importer.apply(\"./logs/generated_logs/1561989897361-4_25.xes\")\n",
    "#a_log50  = xes_importer.apply(\"./logs/generated_logs/1561989897361-4_50.xes\")\n",
    "a_log75  = xes_importer.apply(\"./logs/generated_logs/1561989897313-3_75.xes\")\n",
    "#a_log100 = xes_importer.apply(\"./logs/generated_logs/1561989906794-495_100.xes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCyHXEpuledB"
   },
   "source": [
    "# **Seq2Seq**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "id": "Mu8-KGJm88Kg"
   },
   "outputs": [],
   "source": [
    "log = utils.remove_timezones(a_log75)\n",
    "utils.abstract_time(log, utils.abstract_seconds) # AF\n",
    "c_log, u_log = utils.split_log(log)\n",
    "\n",
    "sparse_log = utils.get_sparse_log(log)\n",
    "sparse_c_log, sparse_u_log = utils.get_sparse_log(c_log), utils.get_sparse_log(u_log)\n",
    "\n",
    "A = list(set([event[\"concept:name\"] for trace in log for event in trace ]))\n",
    "A_set = [[activity] for activity in A] \n",
    "\n",
    "#log_set   = utils.get_sparse_log_set(log)\n",
    "#c_log_set = utils.get_sparse_log_set(c_log)\n",
    "#u_log_set = utils.get_sparse_log_set(u_log)\n",
    "\n",
    "log_set   = utils.get_sparse_log_set_artificial(log)    # AF\n",
    "c_log_set = utils.get_sparse_log_set_artificial(c_log)\n",
    "u_log_set = utils.get_sparse_log_set_artificial(u_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_trace_len = utils.longest_trace(u_log)\n",
    "max_unc_trace_len = utils.longest_trace(u_log_set)\n",
    "max_seq_len = utils.longest_unc_seq(u_log_set)\n",
    "k = max_seq_len # longest uncertain sequences\n",
    "unc_seq = utils.possible_uncertain_seq(A, k) \n",
    "pos_res = utils.possible_resolutions(A, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_res_for_unc_seq = utils.pos_res_for_unc_seq(unc_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add start and end sequence symbol to each target trace\n",
    "BOS = '<'\n",
    "EOS = '>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shrink the set if it is larger 10000 to 10000 \n",
    "# since the smallest set has about 10000 (traffic log) \n",
    "# also for huge encoding 2, 3\n",
    "if len(u_log_set) > 10000:\n",
    "    shuffle(u_log_set)\n",
    "    u_log_set = u_log_set[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_X = [trace[::-1] for trace in u_log_set] \n",
    "y = [[BOS] + seq + [EOS] for seq in sparse_u_log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_events = A\n",
    "target_events = sorted(A + [BOS, EOS])\n",
    "n_enc_tokens = len(input_events)\n",
    "n_dec_tokens = len(target_events)\n",
    "max_enc_seq_len = max([len(trace) for trace in rev_X])\n",
    "max_dec_seq_len = max([len(trace) for trace in y])\n",
    "\n",
    "print('Number of samples:', len(rev_X))\n",
    "print('Number of unique input tokens:', n_enc_tokens)\n",
    "print('Number of unique output tokens:', n_dec_tokens)\n",
    "print('Max sequence length for inputs:', max_enc_seq_len)\n",
    "print('Max sequence length for outputs:', max_dec_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup tables\n",
    "INactivity_to_idx = dict( (tuple(e_set),i) for i,e_set in enumerate(input_events)) \n",
    "INidx_to_activity = dict( (i,tuple(e_set)) for i,e_set in enumerate(input_events))\n",
    "INactivity_to_idx2 = dict( (e_set,i) for i,e_set in enumerate(input_events)) # for decoding\n",
    "INidx_to_activity2 = dict( (i,e_set) for i,e_set in enumerate(input_events)) # for decoding\n",
    "\n",
    "OUTactivity_to_idx = dict( (tuple(e_set),i) for i,e_set in enumerate(target_events))\n",
    "OUTidx_to_activity = dict( (i,tuple(e_set)) for i,e_set in enumerate(target_events))\n",
    "OUTactivity_to_idx2 = dict( (e_set,i) for i,e_set in enumerate(target_events)) # for decoding\n",
    "OUTidx_to_activity2 = dict( (i,e_set) for i,e_set in enumerate(target_events)) # for decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data, decoder_input_data, decoder_target_data = utils.seq2seq_encode(rev_X, y, max_enc_seq_len, n_enc_tokens,\n",
    "                                                                            max_dec_seq_len, n_dec_tokens, INactivity_to_idx,\n",
    "                                                                            OUTactivity_to_idx, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding 2 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_X = [trace_set[::-1] for trace_set in u_log_set]\n",
    "y = [[[BOS]] + seq + [[EOS]] for seq in u_log_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 494\n",
      "Number of unique input tokens: 5984\n",
      "Number of unique output tokens: 88742\n",
      "Max sequence length for inputs: 11\n",
      "Max sequence length for outputs: 13\n"
     ]
    }
   ],
   "source": [
    "input_events = unc_seq\n",
    "target_events = sorted(pos_res + [[BOS], [EOS]])\n",
    "n_enc_tokens = len(input_events)\n",
    "n_dec_tokens = len(target_events)\n",
    "max_enc_seq_len = max([len(trace) for trace in rev_X]) # fix here\n",
    "max_dec_seq_len = max([len(trace) for trace in y])\n",
    "\n",
    "print('Number of samples:', len(rev_X))\n",
    "print('Number of unique input tokens:', n_enc_tokens)\n",
    "print('Number of unique output tokens:', n_dec_tokens)\n",
    "print('Max sequence length for inputs:', max_enc_seq_len)\n",
    "print('Max sequence length for outputs:', max_dec_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup tables\n",
    "unc_seq_to_idx = dict( (tuple(e_set),i) for i,e_set in enumerate(input_events)) \n",
    "idx_to_unc_seq = dict( (i,tuple(e_set)) for i,e_set in enumerate(input_events))\n",
    "\n",
    "pos_res_to_idx = dict( (tuple(e_set),i) for i,e_set in enumerate(target_events))\n",
    "idx_to_pos_res = dict( (i,tuple(e_set)) for i,e_set in enumerate(target_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data, decoder_input_data, decoder_target_data = utils.seq2seq_encode(rev_X, y, max_enc_seq_len, n_enc_tokens,\n",
    "                                                                            max_dec_seq_len, n_dec_tokens, unc_seq_to_idx,\n",
    "                                                                            pos_res_to_idx, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data, decoder_input_data, decoder_target_data = utils.seq2seq_encode(rev_X, y, max_enc_seq_len, n_enc_tokens,\n",
    "                                                                            max_dec_seq_len, n_dec_tokens, unc_seq_to_idx,\n",
    "                                                                            pos_res_to_idx, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split off the test set (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(rev_X)\n",
    "cut = int(n_samples*0.8)\n",
    "#training\n",
    "train_encoder_input_data  = encoder_input_data[:cut]\n",
    "train_decoder_input_data  = decoder_input_data[:cut]\n",
    "train_decoder_target_data = decoder_target_data[:cut]\n",
    "\n",
    "# test\n",
    "test_encoder_input_data = encoder_input_data[cut:]\n",
    "test_decoder_input_data = decoder_input_data[cut:]\n",
    "test_decoder_target_data = decoder_target_data[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((395, 11, 5984), (99, 11, 5984))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoder_input_data.shape, test_encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (Preprocessing, Training, Predictions, Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "dxp-Ftwkmo1g"
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # batch size for training\n",
    "epochs = 30 # 50  # number of epochs to train for, 100\n",
    "latent_dim = 256  # latent dimensionality of the encoding space\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "RmkvqwgOmyJM"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, n_enc_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, n_dec_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(n_dec_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model(inputs=[encoder_inputs, decoder_inputs], \n",
    "              outputs=decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "I8-Q12F_nTA7"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "sO6MLrLJnu-K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "5/5 [==============================] - 9s 2s/step - loss: 7.0707 - val_loss: 5.1976\n",
      "Epoch 2/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 3.8656 - val_loss: 2.6003\n",
      "Epoch 3/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 2.4323 - val_loss: 2.3007\n",
      "Epoch 4/30\n",
      "5/5 [==============================] - 9s 2s/step - loss: 2.2467 - val_loss: 2.2338\n",
      "Epoch 5/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 2.1818 - val_loss: 2.1918\n",
      "Epoch 6/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 2.1434 - val_loss: 2.1591\n",
      "Epoch 7/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 2.1096 - val_loss: 2.1427\n",
      "Epoch 8/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 2.0813 - val_loss: 2.1152\n",
      "Epoch 9/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 2.0627 - val_loss: 2.0896\n",
      "Epoch 10/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 2.0165 - val_loss: 2.0266\n",
      "Epoch 11/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.9370 - val_loss: 1.9437\n",
      "Epoch 12/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.8470 - val_loss: 1.8690\n",
      "Epoch 13/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.7856 - val_loss: 1.8193\n",
      "Epoch 14/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.7271 - val_loss: 1.7632\n",
      "Epoch 15/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.6854 - val_loss: 1.7392\n",
      "Epoch 16/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.6520 - val_loss: 1.6998\n",
      "Epoch 17/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.6193 - val_loss: 1.6701\n",
      "Epoch 18/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.5984 - val_loss: 1.6701\n",
      "Epoch 19/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.5731 - val_loss: 1.6271\n",
      "Epoch 20/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.5488 - val_loss: 1.6288\n",
      "Epoch 21/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.5324 - val_loss: 1.5965\n",
      "Epoch 22/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.5237 - val_loss: 1.6013\n",
      "Epoch 23/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.4992 - val_loss: 1.5619\n",
      "Epoch 24/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.4750 - val_loss: 1.5558\n",
      "Epoch 25/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.4688 - val_loss: 1.5385\n",
      "Epoch 26/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.4494 - val_loss: 1.5419\n",
      "Epoch 27/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.4416 - val_loss: 1.5142\n",
      "Epoch 28/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.4218 - val_loss: 1.5087\n",
      "Epoch 29/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.4183 - val_loss: 1.4923\n",
      "Epoch 30/30\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.4070 - val_loss: 1.4784\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train_encoder_input_data, train_decoder_input_data],\n",
    "                    train_decoder_target_data,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./outputs/seq2seqsets_bpi14log_logorder_01022021.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjnVDrij6G8Z"
   },
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "25LUuWtbLtyc"
   },
   "outputs": [],
   "source": [
    "#use the trained model to make predictions via inferencing\n",
    "#for that we take the uncertain log as input and assume the order in the log as the correct order\n",
    "\n",
    "#inference mode brakedown\n",
    "# 1 encode input sequence and return corresponding internal states\n",
    "# 2 start decoder with BOS symbol and the encoders internal states as input\n",
    "# 3 append predicted activity (after looking up in lookup table) to the predicted sequence\n",
    "# 4 repeat process with the previously predicted activity and the updated internal states as input\n",
    "# 5 end when EOS was predicted\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_X_test = utils.decode_X(test_encoder_input_data, idx_to_unc_seq, mode=\"enc3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_y_test = utils.decode_y(test_decoder_input_data, idx_to_pos_res, mode='enc2+3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(0,20):\n",
    "    enc_input_seq = test_encoder_input_data[idx:idx+1]\n",
    "    decoded_trace, n_repredicts = decode_seq(enc_input_seq,decoded_X_test[idx][::-1],\n",
    "                                             decoded_y_test[idx][1:-1],\n",
    "                                             pos_res_to_idx,idx_to_pos_res)\n",
    "    print('-'*20)\n",
    "    print('Input trace  :', decoded_X_test[idx][::-1]) # log_set[idx]\n",
    "    print('Target trace :', decoded_y_test[idx][1:-1])\n",
    "    print('Decoded trace:', decoded_trace[:])\n",
    "    print(decoded_y_test[idx][1:-1]==decoded_trace)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uOcpfx5Eut0d",
    "outputId": "cd82052c-654a-4d6f-8d64-d0dce50c6e94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [02:45<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7878787878787878 0.6995827538247567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = len(decoded_X_test)\n",
    "n_event_sets = sum([1 for trace in decoded_X_test for event_set in trace])\n",
    "count = 0\n",
    "count_highest_prob_is_non_pos_res = 0\n",
    "prediction_probabilities = {}\n",
    "actual_resolution_probabilities = {}\n",
    "\n",
    "for idx in tqdm(range(total)):\n",
    "    enc_input_seq = test_encoder_input_data[idx:idx+1]\n",
    "    decoded_trace, n_repredicts = decode_seq(enc_input_seq,decoded_X_test[idx][::-1],\n",
    "                                             decoded_y_test[idx][1:-1],\n",
    "                                             pos_res_to_idx,idx_to_pos_res)\n",
    "    \n",
    "    count_highest_prob_is_non_pos_res += n_repredicts\n",
    "    if decoded_y_test[idx][1:-1] == decoded_trace:\n",
    "        count += 1\n",
    "    #print(decoded_y_test[idx][1:-1]==decoded_trace)\n",
    "print(count / total, count_highest_prob_is_non_pos_res / n_event_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23\n",
      "0.17\n",
      "0.15\n",
      "0.16\n",
      "0.13\n",
      "0.12\n",
      "0.14\n",
      "0.15\n",
      "0.2\n",
      "0.15\n",
      "0.17\n",
      "0.18\n",
      "0.42\n",
      "0.19\n",
      "0.43\n",
      "0.2\n",
      "0.11\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "for act in A:\n",
    "    print(round(statistics.mean(prediction_probabilities[tuple([act])]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23\n",
      "0.17\n",
      "0.15\n",
      "0.16\n",
      "0.13\n",
      "0.12\n",
      "0.14\n",
      "0.15\n",
      "0.2\n",
      "0.15\n",
      "0.17\n",
      "0.18\n",
      "0.42\n",
      "0.19\n",
      "0.43\n",
      "0.2\n",
      "0.11\n"
     ]
    }
   ],
   "source": [
    "for act in A:\n",
    "    print(round(statistics.mean(actual_resolution_probabilities[tuple([act])]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a_file = open(\"Seq2Seq_Enc3_ART1_pred_prob.pkl\", \"wb\")\n",
    "pickle.dump(prediction_probabilities, a_file)\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"Seq2Seq_Enc3_ART1_target_prob.pkl\", \"wb\")\n",
    "pickle.dump(actual_resolution_probabilities, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "z3yY9Mv2TcWV"
   },
   "outputs": [],
   "source": [
    "# build function to decode predictions \n",
    "def decode_seq(enc_input_seq, dec_input_seq, dec_y_test, OUTact_to_idx, OUTidx_to_act):\n",
    "    # encode the input sequence to get the internal state vectors\n",
    "    states_value = encoder_model.predict(enc_input_seq)\n",
    "\n",
    "    # generate empty target sequence of len 1 with only the start character\n",
    "    target_seq = np.zeros((1,1, n_dec_tokens))\n",
    "    target_seq[0, 0, OUTact_to_idx[tuple([BOS])]] = 1.0\n",
    "\n",
    "    #output seq loop\n",
    "    stop_cond = False\n",
    "    decoded_trace = []\n",
    "    num_dec_events = 0\n",
    "    n_repredicts = 0\n",
    "    while not stop_cond:\n",
    "        n_its = 0\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        truth = dec_y_test[num_dec_events]\n",
    "        truth_index = OUTact_to_idx[tuple(truth)]\n",
    "        truth_prob = output_tokens[0, -1, :][truth_index]\n",
    "        actual_resolution_probabilities[tuple(truth)] = actual_resolution_probabilities.get(tuple(truth), []) + [truth_prob]\n",
    "\n",
    "        #sample token and add corresponding activity to the decoded trace\n",
    "        prob = np.amax(output_tokens[0, -1, :])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_activity = list(OUTidx_to_act[sampled_token_index])\n",
    "    \n",
    "        \n",
    "        # check if the sampled activity is actually a possible resolution fo that case\n",
    "        while not sampled_activity in pos_res_for_unc_seq[tuple(dec_input_seq[num_dec_events])]:\n",
    "            if n_its == 0:\n",
    "                n_repredicts += 1\n",
    "                n_its += 1\n",
    "            \n",
    "            # if not take the prediction with the 2nd highest prob... etc.\n",
    "            output_tokens[0, -1, sampled_token_index] = 0.0 # set the old idx with max prob to zero\n",
    "            \n",
    "            prob = np.amax(output_tokens[0, -1, :])\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_activity = list(OUTidx_to_act[sampled_token_index])\n",
    "            \n",
    "        prediction_probabilities[tuple(sampled_activity)] = prediction_probabilities.get(tuple(sampled_activity), []) + [prob]\n",
    "        decoded_trace.append(sampled_activity)\n",
    "        num_dec_events += 1\n",
    "\n",
    "        #check for stop condition: either hitting max length or prediciting EOS\n",
    "        if (sampled_activity == tuple([EOS]) or len(decoded_trace) > max_dec_seq_len or\n",
    "            num_dec_events >= len(dec_input_seq) ):\n",
    "            stop_cond = True\n",
    "\n",
    "        #update the target sequence (len 1) to resemble the last predicted event\n",
    "        target_seq = np.zeros((1, 1, n_dec_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        #update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_trace, n_repredicts"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "DDolyTrXjww-",
    "4hlJOE2H-CBh"
   ],
   "name": "Seq2Seq.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "17fbd2a891c246b1ad644861df42aa9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c6ec3586c3e24fac9ab8124f2a508250",
       "IPY_MODEL_b2b5c49f02404eb29bb2b33b3f7b5d64"
      ],
      "layout": "IPY_MODEL_c4b08832d5274e6abdceb831e0bbe4d1"
     }
    },
    "7c1f1a33df154d5bace2efc5e29f6b6a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8033e5669f8e4a359a802bbd3e056518": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4e455a34a5e47f99b310614cf320832": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2b5c49f02404eb29bb2b33b3f7b5d64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c1f1a33df154d5bace2efc5e29f6b6a",
      "placeholder": "​",
      "style": "IPY_MODEL_a4e455a34a5e47f99b310614cf320832",
      "value": " 41353/41353 [00:16&lt;00:00, 2454.94it/s]"
     }
    },
    "c4b08832d5274e6abdceb831e0bbe4d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6ec3586c3e24fac9ab8124f2a508250": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "parsing log, completed traces :: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8033e5669f8e4a359a802bbd3e056518",
      "max": 41353,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e0aa799ebe894bf380c94bdcda32c76b",
      "value": 41353
     }
    },
    "e0aa799ebe894bf380c94bdcda32c76b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
