{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aprYXuoCjDM7"
   },
   "source": [
    "# **Resolving Partially Ordered Traces Using Deep Learning** (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZQouEa5jNye"
   },
   "source": [
    "|                        | BPI 2012| BPI 2014 | Traffic | <br>\n",
    "|------------------------|---------|----------|---------|\n",
    "| \\|A\\|                  | 24      |  9       | 11      |\n",
    "| #Traces                | 13087   | 41353    | 150370  |\n",
    "| #Events                | 262200  | 369485   | 561470  |\n",
    "| #Event Sets            | 248205  | 243186   | 549452  |\n",
    "| #uncertain Seq's       | 14      | 24       | 25      |\n",
    "| Trace Uncertainty      | 38%     | 93%      |  6%     |\n",
    "| Event Uncertainty      |  5%     | 40%      |  2%     |\n",
    "| max(len(unc.seq))      |  4      |  4       |  3      |\n",
    "| avg(len(unc.seq))      |  2.4    |  2.6     |  2.0    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDolyTrXjww-"
   },
   "source": [
    "### imports and PIP installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7lUJcTbHisjt",
    "outputId": "16e5488e-a90e-41f0-fb2d-b20b985a4dc9"
   },
   "outputs": [],
   "source": [
    "from pm4py.objects.log.importer.xes import importer as xes_importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from encoder import Encoder1, Encoder2, Encoder3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jg352xL9j8bX"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from random import randint, shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWVB1eLrkdXa"
   },
   "source": [
    "### Loading the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "c040117d405345a2bd6967d1e4ba55cd",
      "360f2fe289f94b3685f0f47105941ed2",
      "75a588a2368c46888b4a8629e0cd2c5f",
      "3fa9421b37bf453fae3fa973ca7130f7",
      "357a4c8a8373480684caa29a2047d9b9",
      "07d847f482ca4986ad80214cb78b91f8",
      "d83b86a7fbb243c6a61184cd90dfd62e",
      "feb1877ac06b44c4ac2903710feb8d1e"
     ]
    },
    "id": "C3epvnhckc3z",
    "outputId": "dea3a107-d79d-4ab5-da4b-c7e42630324e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baac34c2659a41b7a16fc3bd39e7ab31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='parsing log, completed traces :: ', max=150370.0, style=Pâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# real life logs\n",
    "\n",
    "#b12_log = xes_importer.apply(\"./logs/BPI_Challenge_2012.xes\")\n",
    "#b14_log = xes_importer.apply(\"./logs/BPI_Challenge_2014.xes\")\n",
    "traffic_log = xes_importer.apply(\"./logs/traffic_fines.xes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificial logs\n",
    "\n",
    "#a_log0   = xes_importer.apply(\"./logs/generated_logs/1561989897361-4_0.xes\")\n",
    "#a_log25  = xes_importer.apply(\"./logs/generated_logs/1561989897361-4_25.xes\")\n",
    "#a_log50  = xes_importer.apply(\"./logs/generated_logs/1561989897361-4_50.xes\")\n",
    "#a_log75  = xes_importer.apply(\"./logs/generated_logs/1561989897313-3_75.xes\")\n",
    "#a_log100 = xes_importer.apply(\"./logs/generated_logs/1561989906794-495_100.xes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRd2KhUo72bq"
   },
   "source": [
    "# **Vanilla LSTM**\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Mu8-KGJm88Kg"
   },
   "outputs": [],
   "source": [
    "log = utils.remove_timezones(traffic_log)\n",
    "#utils.abstract_time(log, utils.abstract_seconds) # AF\n",
    "sparse_log = utils.get_sparse_log(log)\n",
    "A = list(set([event[\"concept:name\"] for trace in log for event in trace ]))\n",
    "c_log, u_log = utils.split_log(log) \n",
    "\n",
    "A_set = [[activity] for activity in A]        \n",
    "\n",
    "#log_set   = utils.get_sparse_log_set(log) \n",
    "#c_log_set = utils.get_sparse_log_set(c_log)\n",
    "#u_log_set = utils.get_sparse_log_set(u_log)\n",
    "\n",
    "log_set   = utils.get_sparse_log_set_artificial(log)    # AF\n",
    "c_log_set = utils.get_sparse_log_set_artificial(c_log)\n",
    "u_log_set = utils.get_sparse_log_set_artificial(u_log)\n",
    "\n",
    "enc1 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "max_trace_len = utils.longest_trace(log)\n",
    "max_unc_trace_len = utils.longest_trace(log_set)\n",
    "max_seq_len = utils.longest_unc_seq(log_set)\n",
    "k = max_seq_len # longest uncertain sequences\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unc_seq = utils.possible_uncertain_seq(A, k) \n",
    "pos_res = utils.possible_resolutions(A, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_res_for_unc_seq = utils.pos_res_for_unc_seq(unc_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 18, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_trace_len, max_unc_trace_len, max_seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature space reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca, ua = utils.check_unc_activities(log_set, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ca), len(ua), len(log_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = [e for e in ca] + [e for e in ua]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(B) == sorted(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8naVPK-N_d-B"
   },
   "source": [
    "\n",
    "### Encoding 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_u_log = utils.get_sparse_log(u_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling before encoding, due to ambiguous decoding\n",
    "c = list(zip(u_log_set, sparse_u_log))\n",
    "shuffle(c)\n",
    "u_log_set, sparse_u_log = zip(*c)\n",
    "u_log_set, sparse_u_log = list(u_log_set), list(sparse_u_log)\n",
    "\n",
    "enc1 = True\n",
    "\n",
    "if len(u_log_set) > 10000:\n",
    "    u_log_set = u_log_set[:10000]\n",
    "    sparse_u_log = sparse_u_log[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "INenc = Encoder1(A, max_trace_len, True, False)\n",
    "OUTenc = Encoder1(A, max_trace_len, False, True)\n",
    "\n",
    "enc_inputs = INenc.one_hot_encode_log(u_log_set)\n",
    "enc_targets = OUTenc.one_hot_encode_log(sparse_u_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(u_log_set) > 10000:\n",
    "    shuffle(u_log_set)\n",
    "    u_log_set = u_log_set[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "INenc = Encoder2(unc_seq, max_trace_len, True)\n",
    "OUTenc = Encoder2(pos_res, max_trace_len, False)\n",
    "\n",
    "enc_inputs = INenc.one_hot_encode_log(u_log_set)\n",
    "enc_targets = OUTenc.one_hot_encode_log(u_log_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(u_log_set) > 10000:\n",
    "    shuffle(u_log_set)\n",
    "    u_log_set = u_log_set[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "INenc = Encoder3(unc_seq, max_trace_len, True)\n",
    "OUTenc = Encoder3(pos_res, max_trace_len, False)\n",
    "\n",
    "enc_inputs = INenc.one_hot_encode_log(u_log_set)\n",
    "enc_targets = OUTenc.one_hot_encode_log(u_log_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbhTrulc_Qis"
   },
   "source": [
    "## Model (Preprocessing, Training, Predictions, Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dageiSoMVYhX",
    "outputId": "68bdef6e-9d20-459c-ce0f-3430abb42506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9166 20 363 1463\n",
      "(9166, 20, 363) (9166, 20, 1463)\n"
     ]
    }
   ],
   "source": [
    "# prepare specification values\n",
    "n_samples = enc_inputs.shape[0]    # len(log_set)\n",
    "mtl = enc_inputs.shape[1]\n",
    "n_features_in = enc_inputs.shape[2]    # len(unc_seq)\n",
    "n_features_out = enc_targets.shape[2]    # len(pos_res)\n",
    "X, y = enc_inputs, enc_targets\n",
    "print(n_samples, mtl, n_features_in, n_features_out)\n",
    "print(enc_inputs.shape, enc_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "4DUV0gLF9a7Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 20, 20)            30720     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 20, 1463)          30723     \n",
      "=================================================================\n",
      "Total params: 61,443\n",
      "Trainable params: 61,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# if encoding1, then set shuffle=False since the encoding 1 has some ambiguouities\n",
    "# --> we need the indexes of the unencoded data to check if a prediction corresponds to \n",
    "# the ground truth (i.e. check if the predicted, decoded vector matches the unencoded vector)\n",
    "\n",
    "if enc1:\n",
    "    cut = int(n_samples*0.8)\n",
    "    X_train_full, X_test, y_train_full, y_test = X[:cut], X[cut:], y[:cut], y[cut:] \n",
    "    \n",
    "    # get new test samples \n",
    "    sparse_u_log2 = utils.get_sparse_log(u_log)\n",
    "    u_log_set2 = utils.get_sparse_log_set(u_log)\n",
    "    \n",
    "    test_start_idx = n_samples - len(X_test)\n",
    "    dec_X_test = u_log_set2[test_start_idx:]\n",
    "    dec_y_test = sparse_u_log2[test_start_idx:]\n",
    "else:\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "\n",
    "# split train into train and validation data\n",
    "valid_index = int(len(X_train_full)/100*10)          # make valid data 10% and train data the rest\n",
    "X_valid, X_train = X_train_full[:valid_index], X_train_full[valid_index:]\n",
    "y_valid, y_train = y_train_full[:valid_index], y_train_full[valid_index:]\n",
    "\n",
    "# set up model\n",
    "n_neurons = mtl\n",
    "n_epoch = 30\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape=(mtl, n_features_in), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features_out, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])# maybe use loss='categorical_crossentropy'\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ei7rGz6c71yd",
    "outputId": "306e58a8-2d8f-41d3-f209-41f691a7b80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "207/207 [==============================] - 10s 51ms/step - loss: 0.5815 - categorical_accuracy: 0.0428 - val_loss: 0.3369 - val_categorical_accuracy: 0.0430\n",
      "Epoch 2/30\n",
      "207/207 [==============================] - 9s 46ms/step - loss: 0.2618 - categorical_accuracy: 0.0558 - val_loss: 0.2171 - val_categorical_accuracy: 0.0576\n",
      "Epoch 3/30\n",
      "207/207 [==============================] - 10s 47ms/step - loss: 0.1979 - categorical_accuracy: 0.0579 - val_loss: 0.1833 - val_categorical_accuracy: 0.0576\n",
      "Epoch 4/30\n",
      "207/207 [==============================] - 10s 48ms/step - loss: 0.1693 - categorical_accuracy: 0.0630 - val_loss: 0.1537 - val_categorical_accuracy: 0.0735\n",
      "Epoch 5/30\n",
      "207/207 [==============================] - 9s 45ms/step - loss: 0.1389 - categorical_accuracy: 0.0733 - val_loss: 0.1233 - val_categorical_accuracy: 0.0741\n",
      "Epoch 6/30\n",
      "207/207 [==============================] - 9s 46ms/step - loss: 0.1102 - categorical_accuracy: 0.0813 - val_loss: 0.0913 - val_categorical_accuracy: 0.0965\n",
      "Epoch 7/30\n",
      "207/207 [==============================] - 9s 45ms/step - loss: 0.0811 - categorical_accuracy: 0.0942 - val_loss: 0.0663 - val_categorical_accuracy: 0.0990\n",
      "Epoch 8/30\n",
      "207/207 [==============================] - 9s 45ms/step - loss: 0.0604 - categorical_accuracy: 0.0992 - val_loss: 0.0489 - val_categorical_accuracy: 0.1033\n",
      "Epoch 9/30\n",
      "207/207 [==============================] - 9s 45ms/step - loss: 0.0462 - categorical_accuracy: 0.1017 - val_loss: 0.0377 - val_categorical_accuracy: 0.1046\n",
      "Epoch 10/30\n",
      "207/207 [==============================] - 10s 48ms/step - loss: 0.0364 - categorical_accuracy: 0.1035 - val_loss: 0.0297 - val_categorical_accuracy: 0.1066\n",
      "Epoch 11/30\n",
      "207/207 [==============================] - 10s 46ms/step - loss: 0.0290 - categorical_accuracy: 0.1058 - val_loss: 0.0236 - val_categorical_accuracy: 0.1088\n",
      "Epoch 12/30\n",
      "207/207 [==============================] - 10s 46ms/step - loss: 0.0234 - categorical_accuracy: 0.1071 - val_loss: 0.0193 - val_categorical_accuracy: 0.1089\n",
      "Epoch 13/30\n",
      "207/207 [==============================] - 9s 46ms/step - loss: 0.0193 - categorical_accuracy: 0.1071 - val_loss: 0.0160 - val_categorical_accuracy: 0.1089\n",
      "Epoch 14/30\n",
      "207/207 [==============================] - 10s 47ms/step - loss: 0.0160 - categorical_accuracy: 0.1075 - val_loss: 0.0134 - val_categorical_accuracy: 0.1095\n",
      "Epoch 15/30\n",
      "207/207 [==============================] - 9s 45ms/step - loss: 0.0135 - categorical_accuracy: 0.1080 - val_loss: 0.0115 - val_categorical_accuracy: 0.1097\n",
      "Epoch 16/30\n",
      "207/207 [==============================] - 9s 45ms/step - loss: 0.0114 - categorical_accuracy: 0.1082 - val_loss: 0.0099 - val_categorical_accuracy: 0.1098\n",
      "Epoch 17/30\n",
      "207/207 [==============================] - 10s 46ms/step - loss: 0.0096 - categorical_accuracy: 0.1086 - val_loss: 0.0086 - val_categorical_accuracy: 0.1100\n",
      "Epoch 18/30\n",
      "207/207 [==============================] - 10s 46ms/step - loss: 0.0082 - categorical_accuracy: 0.1089 - val_loss: 0.0077 - val_categorical_accuracy: 0.1098\n",
      "Epoch 19/30\n",
      "207/207 [==============================] - 10s 47ms/step - loss: 0.0071 - categorical_accuracy: 0.1092 - val_loss: 0.0068 - val_categorical_accuracy: 0.1104\n",
      "Epoch 20/30\n",
      "207/207 [==============================] - 10s 46ms/step - loss: 0.0062 - categorical_accuracy: 0.1093 - val_loss: 0.0062 - val_categorical_accuracy: 0.1104\n",
      "Epoch 21/30\n",
      "207/207 [==============================] - 10s 46ms/step - loss: 0.0054 - categorical_accuracy: 0.1094 - val_loss: 0.0055 - val_categorical_accuracy: 0.1104\n",
      "Epoch 22/30\n",
      "207/207 [==============================] - 9s 46ms/step - loss: 0.0048 - categorical_accuracy: 0.1095 - val_loss: 0.0051 - val_categorical_accuracy: 0.1104\n",
      "Epoch 23/30\n",
      "207/207 [==============================] - 9s 45ms/step - loss: 0.0042 - categorical_accuracy: 0.1096 - val_loss: 0.0047 - val_categorical_accuracy: 0.1104\n",
      "Epoch 24/30\n",
      "207/207 [==============================] - 10s 46ms/step - loss: 0.0038 - categorical_accuracy: 0.1096 - val_loss: 0.0043 - val_categorical_accuracy: 0.1104\n",
      "Epoch 25/30\n",
      "207/207 [==============================] - 9s 46ms/step - loss: 0.0034 - categorical_accuracy: 0.1096 - val_loss: 0.0040 - val_categorical_accuracy: 0.1104\n",
      "Epoch 26/30\n",
      "207/207 [==============================] - 9s 46ms/step - loss: 0.0030 - categorical_accuracy: 0.1097 - val_loss: 0.0037 - val_categorical_accuracy: 0.1104\n",
      "Epoch 27/30\n",
      "207/207 [==============================] - 9s 45ms/step - loss: 0.0027 - categorical_accuracy: 0.1097 - val_loss: 0.0035 - val_categorical_accuracy: 0.1104\n",
      "Epoch 28/30\n",
      "207/207 [==============================] - 9s 45ms/step - loss: 0.0025 - categorical_accuracy: 0.1097 - val_loss: 0.0032 - val_categorical_accuracy: 0.1106\n",
      "Epoch 29/30\n",
      "207/207 [==============================] - 9s 46ms/step - loss: 0.0023 - categorical_accuracy: 0.1097 - val_loss: 0.0031 - val_categorical_accuracy: 0.1106\n",
      "Epoch 30/30\n",
      "207/207 [==============================] - 10s 47ms/step - loss: 0.0020 - categorical_accuracy: 0.1098 - val_loss: 0.0028 - val_categorical_accuracy: 0.1106\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=n_epoch,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Y3a34UK3vFQ"
   },
   "outputs": [],
   "source": [
    "model.save('./outputs/LSTMsets_trafficlog_split_logorder_07022021.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sLt35sD_tHD",
    "outputId": "1f8dc392-59ef-4ea7-b1c3-f39132e98235"
   },
   "outputs": [],
   "source": [
    "# decode , Xtest, ytest\n",
    "if enc1:\n",
    "    # get new test samples \n",
    "    sparse_u_log2 = utils.get_sparse_log(u_log)\n",
    "    u_log_set2 = utils.get_sparse_log_set(u_log)\n",
    "    \n",
    "    test_start_idx = n_samples - len(X_test)\n",
    "    dec_X_test = u_log_set2[test_start_idx:]\n",
    "    dec_y_test = sparse_u_log2[test_start_idx:]\n",
    "else:\n",
    "    dec_X_test = utils.decode_X(X_test, INenc.idx_to_activity, mode='enc3') # mode: event or event_set\n",
    "    dec_y_test = utils.decode_y(y_test, OUTenc.idx_to_activity, mode='enc2+3') # mode: event or event_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_event_sets = 0\n",
    "for trace in dec_X_test:\n",
    "    for event_set in trace:\n",
    "        n_event_sets += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1834/1834 [01:54<00:00, 16.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# evaluate test set\n",
    "acc, non_pos_res, prediction_probabilities, actual_resolution_probabilities = eval_test(model, X_test, dec_y_test, dec_X_test, n_event_sets,\n",
    "                                                       OUTenc.idx_to_activity, OUTenc.activity_to_idx, pos_res_for_unc_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0019782393669634025)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, non_pos_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n",
      "1.0\n",
      "0.99\n",
      "0.98\n",
      "0.95\n",
      "1.0\n",
      "1.0\n",
      "0.99\n",
      "0.94\n",
      "0.85\n",
      "0.83\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "for act in A:\n",
    "    print(round(statistics.mean(prediction_probabilities[tuple([act])]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89\n",
      "1.0\n",
      "0.99\n",
      "0.98\n",
      "0.95\n",
      "1.0\n",
      "1.0\n",
      "0.99\n",
      "0.94\n",
      "0.85\n",
      "0.83\n"
     ]
    }
   ],
   "source": [
    "for act in A:\n",
    "    print(round(statistics.mean(actual_resolution_probabilities[tuple([act])]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a_file = open(\"LSTM_ENC3_TRAFFIC_pred_prob.pkl\", \"wb\")\n",
    "pickle.dump(prediction_probabilities, a_file)\n",
    "a_file.close()\n",
    "\n",
    "a_file = open(\"LSTM_ENC3_TRAFFIC_target_prob.pkl\", \"wb\")\n",
    "pickle.dump(actual_resolution_probabilities, a_file)\n",
    "a_file.close()\n",
    "#a_file = open(\"LSTM_ENC2_BPIC14.pkl\", \"rb\")\n",
    "#output = pickle.load(a_file)\n",
    "#a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test(model, X_test, dec_y_test, dec_X_test, n_event_sets, \n",
    "              idx_to_act: dict, act_to_idx: dict, pos_res_for_unc_seq: dict) -> float:\n",
    "    total = X_test.shape[0]\n",
    "    count = 0\n",
    "    count_highest_prob_is_non_pos_res = 0\n",
    "    prediction_probabilities = {}\n",
    "    actual_resolution_probabilities = {}\n",
    "    \n",
    "    for i in tqdm(range(total)): #go over every trace in the evaluation log\n",
    "        \n",
    "        #get a prediction for the correct ordering of the current trace\n",
    "        result = model.predict(X_test[i].reshape(1, X_test[i].shape[0], X_test[i].shape[1]))\n",
    "        predicted_trace = []\n",
    "\n",
    "        for l in range(result.shape[1]):\n",
    "            if np.all(X_test[i][l] == 0.0): # ignore padding predictions\n",
    "                predicted_trace.append('-')\n",
    "            else:\n",
    "                # get probability for the truth that is associated by the trained model\n",
    "                truth = dec_y_test[i][l] # i-th trace, l-th event set\n",
    "                truth_index = act_to_idx[tuple(truth)]\n",
    "                truth_prob = result[0][l][truth_index]\n",
    "                actual_resolution_probabilities[tuple(truth)] = actual_resolution_probabilities.get(tuple(truth), []) + [truth_prob]\n",
    "                \n",
    "                n_its = 0 # to monitor whether we went into while loop at least one time, i.e. the frist predction was not a pos res\n",
    "                \n",
    "                prob = np.amax(result[0][l])\n",
    "                idx = np.argmax(result[0][l]) # get idx prediction with highest prob\n",
    "                predicted_event = list(idx_to_act[idx]) # decode into event / sequence\n",
    "                \n",
    "                # check if the prediction is actually a resolution\n",
    "                while not predicted_event in pos_res_for_unc_seq[tuple(sorted(dec_X_test[i][l]))]:\n",
    "                    # if not take the prediction with the 2nd highest prob... etc.\n",
    "                    if n_its == 0:\n",
    "                        count_highest_prob_is_non_pos_res += 1\n",
    "                        n_its += 1\n",
    "                        \n",
    "                    result[0][l][idx] = 0.0 # set the old idx with max prob to zero\n",
    "                    \n",
    "                    prob = np.amax(result[0][l])\n",
    "                    idx = np.argmax(result[0][l])\n",
    "                    predicted_event = list(idx_to_act[idx])\n",
    "                    \n",
    "                    \n",
    "\n",
    "                predicted_trace.append(predicted_event)\n",
    "                prediction_probabilities[tuple(predicted_event)] = prediction_probabilities.get(tuple(predicted_event), []) + [prob]\n",
    "\n",
    "        predicted_trace = predicted_trace[:len(dec_y_test[i])]\n",
    "        \n",
    "        #print(predicted_trace, dec_y_test[i])\n",
    "        if predicted_trace == dec_y_test[i]:\n",
    "            count += 1\n",
    "\n",
    "    return count/total, count_highest_prob_is_non_pos_res/n_event_sets, prediction_probabilities, actual_resolution_probabilities"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TTpdpdRtf8Mq",
    "8w9a7JeIdKcx",
    "8naVPK-N_d-B"
   ],
   "name": "VanillaLSTM",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07d847f482ca4986ad80214cb78b91f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "357a4c8a8373480684caa29a2047d9b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "360f2fe289f94b3685f0f47105941ed2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3fa9421b37bf453fae3fa973ca7130f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_feb1877ac06b44c4ac2903710feb8d1e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d83b86a7fbb243c6a61184cd90dfd62e",
      "value": " 150370/150370 [42:45&lt;00:00, 58.62it/s]"
     }
    },
    "75a588a2368c46888b4a8629e0cd2c5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "parsing log, completed traces :: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07d847f482ca4986ad80214cb78b91f8",
      "max": 150370,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_357a4c8a8373480684caa29a2047d9b9",
      "value": 150370
     }
    },
    "c040117d405345a2bd6967d1e4ba55cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_75a588a2368c46888b4a8629e0cd2c5f",
       "IPY_MODEL_3fa9421b37bf453fae3fa973ca7130f7"
      ],
      "layout": "IPY_MODEL_360f2fe289f94b3685f0f47105941ed2"
     }
    },
    "d83b86a7fbb243c6a61184cd90dfd62e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "feb1877ac06b44c4ac2903710feb8d1e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
